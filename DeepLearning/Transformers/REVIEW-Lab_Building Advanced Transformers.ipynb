{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will: \n",
    "\n",
    "- Implement advanced Transformer models using Keras. \n",
    "\n",
    "- Apply Transformers to real-world sequential data tasks. \n",
    "\n",
    "- Build, train, and evaluate Transformer models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (645.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.0/645.0 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (404 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, pyarrow, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.9.2 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.9 numpy-2.1.3 opt-einsum-3.4.0 optree-0.15.0 protobuf-5.29.4 pyarrow-20.0.0 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.0.1 werkzeug-3.1.3 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.1.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m150.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.2.1 pyparsing-3.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 16:39:09.831873: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-29 16:39:09.833352: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-29 16:39:09.838885: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-29 16:39:09.850903: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745944749.872373     301 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745944749.880411     301 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745944749.904754     301 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745944749.904791     301 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745944749.904793     301 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745944749.904795     301 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-29 16:39:09.914260: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 16:39:55.361807: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 923ms/step - loss: 13.3292\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 899ms/step - loss: 0.2196\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 869ms/step - loss: 0.1982\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 893ms/step - loss: 0.2162\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 881ms/step - loss: 0.1381\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 889ms/step - loss: 0.1149\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 869ms/step - loss: 0.1113\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 883ms/step - loss: 0.1311\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 886ms/step - loss: 0.1417\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 884ms/step - loss: 0.0973\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 893ms/step - loss: 0.0965\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 868ms/step - loss: 0.0732\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 859ms/step - loss: 0.1025\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 860ms/step - loss: 0.1070\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 889ms/step - loss: 0.0929\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 873ms/step - loss: 0.0802\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 889ms/step - loss: 0.0552\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 881ms/step - loss: 0.0460\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 865ms/step - loss: 0.0477\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 867ms/step - loss: 0.0437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fd82c33c800>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 272ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    " \n",
    "\n",
    "# Plot the predictions \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(data, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.show() \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 904ms/step - loss: 7.2913 \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: 1.2275   \n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - loss: 0.6874 \n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.3068   \n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 997ms/step - loss: 0.1842\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 0.0722   \n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2s/step - loss: 0.0439\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 3s/step - loss: 0.0343\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 995ms/step - loss: 0.0314\n",
      "Epoch 10/20\n",
      "\u001b[1m44/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 906ms/step - loss: 0.0258"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here.\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here.\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "28ac4fd81c1d713f83dcd1cdf1d3383ad25ea92873288fe9e978e9a17b314709"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
